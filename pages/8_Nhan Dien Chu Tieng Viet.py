import streamlit as st
import tensorflow as tf
import os
import json
import cv2
import numpy as np
from tensorflow.keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional, Add, Activation
from tensorflow.keras.models import Model
import tensorflow.keras.backend as K
from PIL import Image

# Cáº¥u hÃ¬nh trang
st.set_page_config(page_title="Nháº­n diá»‡n chá»¯ tiáº¿ng Viá»‡t", layout="wide", initial_sidebar_state="expanded")

st.title("ğŸ–¼ï¸ Nháº­n diá»‡n chá»¯ tiáº¿ng Viá»‡t")
st.markdown("Táº£i lÃªn má»™t áº£nh chá»©a vÄƒn báº£n tiáº¿ng Viá»‡t Ä‘á»ƒ nháº­n dáº¡ng.")

# Thiáº¿t láº­p Ä‘Æ°á»ng dáº«n
TRAIN_JSON = "labels.json"

# Äá»c labels Ä‘á»ƒ láº¥y danh sÃ¡ch kÃ½ tá»±
with open(TRAIN_JSON, 'r', encoding='utf8') as f:
    train_labels = json.load(f)

# Táº¡o danh sÃ¡ch kÃ½ tá»±
char_list = set()
for label in train_labels.values():
    char_list.update(set(label))
char_list = sorted(char_list)
st.info(f"Sá»‘ lÆ°á»£ng kÃ½ tá»±: {len(char_list)}")
st.info(f"Danh sÃ¡ch kÃ½ tá»±: {''.join(char_list)}")

# Háº±ng sá»‘
MAX_WIDTH = 2167  # Chiá»u rá»™ng tá»‘i Ä‘a cho áº£nh

# XÃ¢y dá»±ng model CRNN
inputs = Input(shape=(118,MAX_WIDTH,1))

# Block 1
x = Conv2D(64, (3,3), padding='same')(inputs)
x = MaxPool2D(pool_size=3, strides=3)(x)
x = Activation('relu')(x)
x_1 = x

# Block 2
x = Conv2D(128, (3,3), padding='same')(x)
x = MaxPool2D(pool_size=3, strides=3)(x)
x = Activation('relu')(x)
x_2 = x

# Block 3
x = Conv2D(256, (3,3), padding='same')(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x_3 = x

# Block 4
x = Conv2D(256, (3,3), padding='same')(x)
x = BatchNormalization()(x)
x = Add()([x,x_3])
x = Activation('relu')(x)
x_4 = x

# Block 5
x = Conv2D(512, (3,3), padding='same')(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x_5 = x

# Block 6
x = Conv2D(512, (3,3), padding='same')(x)
x = BatchNormalization()(x)
x = Add()([x,x_5])
x = Activation('relu')(x)

# Block 7
x = Conv2D(1024, (3,3), padding='same')(x)
x = BatchNormalization()(x)
x = MaxPool2D(pool_size=(3, 1))(x)
x = Activation('relu')(x)

x = MaxPool2D(pool_size=(3, 1))(x)
squeezed = Lambda(lambda x: K.squeeze(x, 1))(x)

blstm_1 = Bidirectional(LSTM(512, return_sequences=True, dropout=0.2))(squeezed)
blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout=0.2))(blstm_1)

outputs = Dense(len(char_list)+1, activation='softmax')(blstm_2)

# Model cho inference
model = Model(inputs, outputs)

# Build model vá»›i má»™t batch Ä‘áº§u vÃ o
dummy_input = np.zeros((1, 118, MAX_WIDTH, 1))
model(dummy_input)

# Compile model vá»›i CTC loss
model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam')

# Load weights
model.load_weights('model/model_checkpoint_weights.hdf5')

def preprocess_image(image):
    # Chuyá»ƒn Ä‘á»•i PIL Image sang numpy array vÃ  xá»­ lÃ½
    img = np.array(image.convert('L'))
    height, width = img.shape
    img = cv2.resize(img,(int(118/height*width),118))
    height, width = img.shape

    # Äáº£m báº£o giÃ¡ trá»‹ Ä‘á»‡m khÃ´ng Ã¢m
    padding_width = max(0, MAX_WIDTH - width)
    img = np.pad(img, ((0,0),(0, padding_width)), 'median')

    # Xá»­ lÃ½ khi áº£nh quÃ¡ rá»™ng
    if width > MAX_WIDTH:
        img = cv2.resize(img, (MAX_WIDTH, 118))

    img = cv2.GaussianBlur(img, (5,5), 0)
    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 4)
    img = np.expand_dims(img, axis=2)
    img = img/255.

    return np.expand_dims(img, axis=0)

def predict_text(image):
    # Tiá»n xá»­ lÃ½ áº£nh
    img = preprocess_image(image)

    # Dá»± Ä‘oÃ¡n
    prediction = model.predict(img)
    out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1], greedy=True)[0][0])

    # Chuyá»ƒn Ä‘á»•i káº¿t quáº£ thÃ nh text
    pred = ""
    for p in out[0]:
        if int(p) != -1:
            pred += char_list[int(p)]

    return pred

# Upload image
uploaded_file = st.file_uploader("ğŸ“‚ Chá»n má»™t áº£nh chá»©a vÄƒn báº£n tiáº¿ng Viá»‡t...", type=["jpg", "png", "jpeg", "tif"], label_visibility="collapsed")

if uploaded_file is not None:
    # Má»Ÿ áº£nh tá»« file
    image = Image.open(uploaded_file)

    # Hiá»ƒn thá»‹ áº£nh gá»‘c
    st.subheader("ğŸ–¼ï¸ áº¢nh gá»‘c")
    st.image(image, use_container_width=True)

    # Cháº¡y model dá»± Ä‘oÃ¡n
    with st.spinner("ğŸ” Äang nháº­n diá»‡n vÄƒn báº£n..."):
        result = predict_text(image)
        
        # Hiá»ƒn thá»‹ káº¿t quáº£
        st.subheader("âœ… Káº¿t quáº£ nháº­n diá»‡n")
        st.success(result)
else:
    st.info("ğŸ‘‹ ChÃ o má»«ng! Vui lÃ²ng táº£i lÃªn má»™t hÃ¬nh áº£nh Ä‘á»ƒ báº¯t Ä‘áº§u nháº­n diá»‡n vÄƒn báº£n tiáº¿ng Viá»‡t.")
