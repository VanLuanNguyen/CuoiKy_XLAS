import streamlit as st
from PIL import Image
import supervision as sv
from ultralytics import YOLO
import numpy as np

# Khá»Ÿi táº¡o model
# Äáº£m báº£o báº¡n cÃ³ model nháº­n diá»‡n biá»ƒn bÃ¡o táº¡i Ä‘Æ°á»ng dáº«n "model/road_sign_detection_model.onnx"
model = YOLO("model/road_sign_detection_model.onnx")  # DÃ¹ng "/" thay vÃ¬ "\" cho tÆ°Æ¡ng thÃ­ch há»‡ Ä‘iá»u hÃ nh

# Táº¡o annotator
box_annotator = sv.BoxAnnotator(thickness=2) # CÃ³ thá»ƒ Ä‘iá»u chá»‰nh Ä‘á»™ dÃ y cá»§a bounding box
label_annotator = sv.LabelAnnotator(text_color=sv.Color.WHITE, text_scale=0.5, text_thickness=1) # Äiá»u chá»‰nh mÃ u sáº¯c, kÃ­ch thÆ°á»›c chá»¯

# Giao diá»‡n Streamlit
st.title("ğŸš¦ á»¨ng dá»¥ng nháº­n diá»‡n biá»ƒn bÃ¡o giao thÃ´ng")

# NÃºt upload áº£nh
uploaded_file = st.file_uploader("ğŸ“¤ Táº£i lÃªn má»™t áº£nh chá»©a biá»ƒn bÃ¡o", type=["jpg", "jpeg", "png"])

# Náº¿u ngÆ°á»i dÃ¹ng Ä‘Ã£ upload
if uploaded_file is not None:
    # Má»Ÿ áº£nh tá»« file
    image = Image.open(uploaded_file).convert("RGB")

    # Hiá»ƒn thá»‹ áº£nh gá»‘c
    st.subheader("ğŸ–¼ï¸ áº¢nh gá»‘c")
    st.image(image, use_container_width=True)

    # Cháº¡y model dá»± Ä‘oÃ¡n
    with st.spinner("ğŸ” Äang nháº­n diá»‡n biá»ƒn bÃ¡o..."):
        # result = model.predict(image, conf=0.25)[0] # Giá»¯ nguyÃªn hoáº·c Ä‘iá»u chá»‰nh conf náº¿u cáº§n
        # Sá»­a lá»—i tiá»m áº©n náº¿u model.predict tráº£ vá» list rá»—ng hoáº·c Ä‘á»‘i tÆ°á»£ng khÃ´ng mong muá»‘n
        results = model.predict(image, conf=0.25)
        if not results or not results[0].boxes:
            st.warning("âš ï¸ KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c biá»ƒn bÃ¡o nÃ o trong áº£nh vá»›i ngÆ°á»¡ng tin cáº­y hiá»‡n táº¡i.")
            st.stop() # Dá»«ng xá»­ lÃ½ náº¿u khÃ´ng cÃ³ káº¿t quáº£
        
        result = results[0]
        detections = sv.Detections.from_ultralytics(result)

        # Láº¥y tÃªn class tá»« model (náº¿u cÃ³ vÃ  cáº§n thiáº¿t cho labels)
        # Giáº£ sá»­ model.names chá»©a danh sÃ¡ch tÃªn cÃ¡c loáº¡i biá»ƒn bÃ¡o
        labels = [
            f"{model.names[class_id]} {confidence:0.2f}"
            for class_id, confidence in zip(detections.class_id, detections.confidence)
        ]

        # Annotate áº£nh
        annotated_image = np.array(image.copy())  # Äá»•i sang máº£ng Ä‘á»ƒ supervision xá»­ lÃ½
        annotated_image = box_annotator.annotate(scene=annotated_image.copy(), detections=detections)
        annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)

    # Hiá»ƒn thá»‹ áº£nh káº¿t quáº£
    st.subheader("âœ… áº¢nh sau khi nháº­n diá»‡n biá»ƒn bÃ¡o")
    st.image(annotated_image, use_container_width=True)

else:
    st.info("â„¹ï¸ Vui lÃ²ng táº£i lÃªn má»™t áº£nh Ä‘á»ƒ báº¯t Ä‘áº§u nháº­n diá»‡n biá»ƒn bÃ¡o.")